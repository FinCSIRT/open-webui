#############################
# NETWORKS
#############################
networks:
  dokploy-network:
    external: true    # ðŸ‘ˆ Use Dokploy-managed network


#############################
# SERVICES
#############################
services:

  ollama:
    image: ollama/ollama:latest   # ðŸ‘ˆ CPU build for CPX41 (recommended)
    container_name: ollama
    restart: unless-stopped
    tty: true
    networks:
      - dokploy-network           # ðŸ‘ˆ Allow connectivity from WebUI + proxy
    volumes:
      - ollama:/root/.ollama      # ðŸ‘ˆ Persist models + cache

  open-webui:
    container_name: open-webui
    build:
      context: .
      dockerfile: Dockerfile
    image: ghcr.io/open-webui/open-webui:main
    depends_on:
      - ollama
    restart: unless-stopped
    networks:
      - dokploy-network
    volumes:
      - open-webui:/app/backend/data
    environment:
      # ðŸ‘‡ WebUI connects to Ollama via internal docker hostname
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_SECRET_KEY=${WEBUI_SECRET_KEY}
    ports:
      # ðŸ‘‡ Expose Open-WebUI to Dokploy so it can apply HTTPS on port 443
      - "3000:8080"
    extra_hosts:
      - host.docker.internal:host-gateway


#############################
# VOLUMES
#############################
volumes:
  ollama: {}
  open-webui: {}
